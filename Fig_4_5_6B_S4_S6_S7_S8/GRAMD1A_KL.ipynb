{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reserved-influence",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: None not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401,E501\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/compat/__init__.py:26\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     pa_version_under7p0,\n\u001b[1;32m     29\u001b[0m     pa_version_under8p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     pa_version_under14p1,\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/compat/numpy/__init__.py:20\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _nlv \u001b[38;5;241m<\u001b[39m Version(_min_numpy_ver):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis version of pandas is incompatible with numpy < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_min_numpy_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour numpy version is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_np_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease upgrade numpy to >= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_min_numpy_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to use this pandas version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     27\u001b[0m np_long: \u001b[38;5;28mtype\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: this version of pandas is incompatible with numpy < 1.22.4\nyour numpy version is 1.21.5.\nPlease upgrade numpy to >= 1.22.4 to use this pandas version",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Line2D\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rc\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# plt.rcParams['ps.useafm'] = True\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import seaborn objects\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/rcmod.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m palettes\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_theme\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset_defaults\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset_orig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes_style\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_style\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplotting_context\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_context\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_palette\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m _style_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes.facecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/palettes.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m husl\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m desaturate, get_color_cycle\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xkcd_rgb, crayons\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_colormap\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/utils.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_rgb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/__init__.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not built. If you want to import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas from the source directory, you may need to run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython setup.py build_ext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to build the C extensions first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_err\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     get_option,\n\u001b[1;32m     36\u001b[0m     set_option,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     options,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: C extension: None not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import rc\n",
    "import seaborn as sns\n",
    "# plt.rcParams['ps.useafm'] = True\n",
    "# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "# sys.path.append('/DATA/lucaa/software/CLoNe')\n",
    "\n",
    "# from clone import CLoNe\n",
    "# from plot import plot_clusters\n",
    "# from structural_utils import load_md_args, show_cluster_info\n",
    "\n",
    "import mdtraj\n",
    "import pyemma\n",
    "\n",
    "print(__doc__)\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "def calculate_pca(topo, traj, main_folder, syst, at_sel, n_pca ):\n",
    "    # Load trajectory\n",
    "    topology = mdtraj.load(topo).topology\n",
    "    struct_ens = mdtraj.load(traj, top=topo)\n",
    "\n",
    "    # Create result folder based on dataset nam\\e\n",
    "    if not os.path.exists(main_folder):\n",
    "        os.makedirs(main_folder)\n",
    "    out_idx =  1\n",
    "    output_folder = main_folder+\"/%s_%i/\"\n",
    "    while os.path.exists(output_folder%(syst, out_idx)):\n",
    "        out_idx += 1\n",
    "    output_folder = output_folder%(syst, out_idx)\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "\n",
    "    selection = struct_ens.topology.select(at_sel)\n",
    "    coords = struct_ens.xyz[:, selection]\n",
    "    coords = coords.reshape(coords.shape[0], coords.shape[1] * coords.shape[2])\n",
    "    headers = [\"C%i\"%x for x in range(len(coords[0]))]  # general headers\n",
    "\n",
    "    # Principal component analysis\n",
    "    original_coords = coords.copy()\n",
    "    pca_obj = PCA(n_components=n_pca)\n",
    "    reddim_coords = pca_obj.fit_transform(coords)\n",
    "    eigenvalues = pca_obj.explained_variance_ratio_\n",
    "    ratio = np.sum(eigenvalues[:n_pca])\n",
    "    pca_headers = [\"PC%i (%.2f)\"%(x + 1, eigenvalues[x]) for x in range(n_pca)]\n",
    "    \n",
    "    print(\"> PCA: %i => %i dimension(s) with eigenval.: %s\"%(len(headers), n_pca, str(eigenvalues)))\n",
    "    print(\"sum of Variance: %s\"%(np.sum(eigenvalues)))\n",
    "    with open(\"%sPCA_coords.txt\"%output_folder, \"w\") as f:\n",
    "        for x in range(n_pca):\n",
    "            f.write(\"PC%i(%.2f) \"%(x + 1, eigenvalues[x]))\n",
    "        f.write(\"\\n\")\n",
    "        for el in reddim_coords:\n",
    "            for n in el:\n",
    "                f.write(\"%f \"%n)\n",
    "            f.write(\"\\n\")  \n",
    "    return pca_obj, reddim_coords, original_coords\n",
    "\n",
    "\n",
    "def calc_magn_vector(pc):\n",
    "    final_length = int(len(pc)/3)\n",
    "    pc_magn = np.empty(final_length)\n",
    "    \n",
    "    for i in range(final_length):\n",
    "        pc_magn[i] = np.sqrt(pc[i*3]**2+pc[i*3+1]**2+pc[i*3+2]**2)\n",
    "    \n",
    "    return pc_magn\n",
    "\n",
    "\n",
    "def save_pc_bfact(init_padding, length_pc, final_padding, structure, pc_component, outpdb):\n",
    "\n",
    "    pc_elongated = np.concatenate((np.zeros(init_padding),calc_magn_vector(pc_component),np.zeros(final_padding)))\n",
    "    system_length_res = len([residue for residue in structure.topology.residues])\n",
    "    system_length_atoms = len([ atom for atom in structure.topology.atoms])\n",
    "\n",
    "    syst_bfact=np.zeros(system_length_atoms)\n",
    "    index=0\n",
    "    for resid in range(system_length_res):\n",
    "        res_len = len(structure.topology.select('resid '+str(resid)))\n",
    "        res_bfact= res_len\n",
    "        syst_bfact[index:index+res_len] = pc_elongated[resid]\n",
    "        index += res_len\n",
    "\n",
    "    structure[0].save_pdb(outpdb, bfactors=syst_bfact*100)\n",
    "    \n",
    "# Check convercence PC\n",
    "def calculate_pca_convergence(topo, traj, main_folder, syst, at_sel, n_pca, nframes, nsim ):\n",
    "    # Load trajectory\n",
    "    topology = mdtraj.load(topo).topology\n",
    "    struct_ens = mdtraj.load(traj, top=topo)\n",
    "\n",
    "    # Create result folder based on dataset nam\\e\n",
    "    if not os.path.exists(main_folder):\n",
    "        os.makedirs(main_folder)\n",
    "    out_idx =  1\n",
    "    output_folder = main_folder+\"/%s_%i/\"\n",
    "    while os.path.exists(output_folder%(syst, out_idx)):\n",
    "        out_idx += 1\n",
    "    output_folder = output_folder%(syst, out_idx)\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "    selection = struct_ens.topology.select(at_sel)\n",
    "    coords = struct_ens.xyz[:, selection]\n",
    "    coords = coords.reshape(coords.shape[0], coords.shape[1] * coords.shape[2])\n",
    "    headers = [\"C%i\"%x for x in range(len(coords[0]))]  # general headers\n",
    "    \n",
    "    frameslist = np.multiply(np.arange(1,nsim+1),nframes)\n",
    "    original_coords = coords.copy()\n",
    "    pcas_list = []\n",
    "    reddim_coords_list = []\n",
    "    print(np.shape(coords))\n",
    "    # Principal component analysis\n",
    "    for section in frameslist:\n",
    "        pca_obj = PCA(n_components=n_pca)\n",
    "        \n",
    "        reddim_coords = pca_obj.fit_transform(coords[0:section])\n",
    "        pcas_list.append(pca_obj)\n",
    "        #eigenvalues = pca_obj.explained_variance_ratio_\n",
    "        #ratio = np.sum(eigenvalues[:n_pca])\n",
    "        #pca_headers = [\"PC%i (%.2f)\"%(x + 1, eigenvalues[x]) for x in range(n_pca)]\n",
    "    \n",
    "        #print(\"> PCA: %i => %i dimension(s) with eigenval.: %s\"%(len(headers), n_pca, str(eigenvalues)))\n",
    "        #print(\"sum of Variance: %s\"%(np.sum(eigenvalues)))\n",
    "  \n",
    "    return pcas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "muslim-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS SETUP\n",
    "\n",
    "# Clustering parameters \n",
    "pdc=3.5   # neighbour search during clusterint\n",
    "n_resize=4 \n",
    "filt=0.1 \n",
    "verbose=False\n",
    "n_pca=10 # number of PC to include in calculations \n",
    "n_bins= 200  # number of bins for PC hist\n",
    "# Simulations and topology \n",
    "trj_apo='apo/trjcat_md_astera_apo_center_pbcmol_fit_rot_trans_CA_after10ns_stride10.xtc'   # apo traj\n",
    "trj_holo='holo/holo_prot.xtc'  # holo traj\n",
    "trj_tot='astera_tot.xtc'   # concatenated total traj\n",
    "\n",
    "topo_apo='apo.gro'  # pdb or gro of apo\n",
    "\n",
    "# Selection for PCA calculation (see mdtraj syntax)\n",
    "at_sel=\"name CA and residue 374 to 534\"  # try to exclude end loops or regions that move but are not interesting (hides the true PC)\n",
    "n_res=160   # number of residues (still manual insertion, i know...)\n",
    "resmin=374\n",
    "resmax=534\n",
    "feat=\"None\"\n",
    "\n",
    "output_folder = \"results_div\"\n",
    "\n",
    "apo_name=\"apo\"\n",
    "holo_name=\"holo\"\n",
    "tot_name=\"tot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southwest-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> PCA: 483 => 10 dimension(s) with eigenval.: [0.1792123  0.11973875 0.08370548 0.06231228 0.0473187  0.04409574\n",
      " 0.03407646 0.02994204 0.0261161  0.0249496 ]\n",
      "sum of Variance: 0.6514675\n",
      "> PCA: 483 => 10 dimension(s) with eigenval.: [0.21427467 0.13883297 0.08015925 0.05711839 0.05020268 0.04093185\n",
      " 0.03756292 0.02969201 0.02788982 0.02247912]\n",
      "sum of Variance: 0.69914365\n",
      "> PCA: 483 => 10 dimension(s) with eigenval.: [0.17437395 0.14128675 0.06386527 0.05748935 0.05466145 0.04443454\n",
      " 0.03584496 0.03262374 0.02790473 0.02248705]\n",
      "sum of Variance: 0.65497184\n"
     ]
    }
   ],
   "source": [
    "# make results folder \n",
    "try:\n",
    "    os.mkdir(output_folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "# make images folder \n",
    "try:\n",
    "    os.mkdir(output_folder+'/IMAGES/')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "# Calculate PCA\n",
    "pca_apo, red_dim_coords_apo, orig_coords_apo = calculate_pca(topo_apo, trj_apo, output_folder, apo_name, at_sel, n_pca)\n",
    "pca_holo, red_dim_coords_holo, orig_coords_holo = calculate_pca(topo_apo, trj_holo, output_folder, holo_name, at_sel, n_pca)\n",
    "pca_tot, red_dim_coords_tot, orig_coords_tot = calculate_pca(topo_apo, trj_tot, output_folder, tot_name, at_sel, n_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "369ba52a-d31c-4e03-8ef3-9b5844e14731",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_apo_end=np.shape(red_dim_coords_apo)[0]\n",
    "index_tot_end=np.shape(red_dim_coords_tot)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6fd3ad-2ead-4725-98bc-6a0b8c8d3309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.13660804097619783\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Define two probability distributions (can be arrays, lists, or pandas Series)\n",
    "p = np.array(red_dim_coords_tot[0:index_apo_end,0])\n",
    "q = np.array(red_dim_coords_tot[index_apo_end:index_tot_end,0])\n",
    "\n",
    "# Compute histograms to estimate the probability distributions\n",
    "hist1, bin_edges1 = np.histogram(p, bins=200, density=True)\n",
    "hist2, bin_edges2 = np.histogram(q, bins=200, density=True)\n",
    "\n",
    "# Add a small constant to avoid zero values\n",
    "epsilon = 1e-10\n",
    "hist1 = hist1 + epsilon\n",
    "hist2 = hist2 + epsilon\n",
    "\n",
    "# Normalize distributions to ensure they sum to 1\n",
    "hist1 /= np.sum(hist1)\n",
    "hist2 /= np.sum(hist2)\n",
    "\n",
    "\n",
    "# Compute KL divergence\n",
    "kl_divergence1 = entropy(hist1, hist2)\n",
    "kl_divergence2 = entropy(hist2, hist1)\n",
    "\n",
    "kl_divergence = (kl_divergence1 + kl_divergence2) / 2\n",
    "\n",
    "print(f\"KL Divergence: {kl_divergence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3de24-7bea-46a6-b2b1-690e9f066666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
